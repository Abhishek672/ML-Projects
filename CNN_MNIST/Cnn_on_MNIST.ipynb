{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abhisheknegi672@gmail.com_13.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sosRB--jrRvz",
        "outputId": "7b3f4e54-12dd-4af7-c752-6eea1faa0bb1"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras import backend as k\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,AveragePooling2D,Dropout,BatchNormalization\n",
        "from keras.activations import relu,softmax\n",
        "from keras.initializers import he_normal,glorot_normal,random_normal,glorot_uniform\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adadelta,Adam\n",
        "from prettytable import PrettyTable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.utils import np_utils \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfvZEOM_v2Oi"
      },
      "source": [
        "### Data overview:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "rWE8ROOVv1et",
        "outputId": "48d6c5f7-63cd-43eb-9ce4-d5d35cf87523"
      },
      "source": [
        "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
        "print(\"train data shape {}\".format(X_train.shape))\n",
        "print(\"test data shape {}\".format(X_test.shape))\n",
        "rows=X_train.shape[1]\n",
        "columns=X_train.shape[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "train data shape (60000, 28, 28)\n",
            "test data shape (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4rBDsONwokb"
      },
      "source": [
        "### Transforming our input data according to the type of bckend we are using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfbkZm-qwwHR"
      },
      "source": [
        "if k.image_data_format()=='channels_first':\n",
        "  X_train=X_train.reshape(X_train.shape[0],1,rows,columns)\n",
        "  X_test=X_test.reshape(X_test.shape[0],1,rows,columns)\n",
        "  input_shape=(1,rows,columns)\n",
        "else :\n",
        "  X_train=X_train.reshape(X_train.shape[0],rows,columns,1)\n",
        "  X_test=X_test.reshape(X_test.shape[0],rows,columns,1)\n",
        "  input_shape=(rows,columns,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eqs6zqCxn24"
      },
      "source": [
        "### Data normalization and conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "kOQXnRkxxnWM",
        "outputId": "fd48e366-7b33-41d5-d6d0-d0af6cca939d"
      },
      "source": [
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "#converting the class labels to 10 dimensions \n",
        "y_train=np_utils.to_categorical(y_train,10)\n",
        "y_test=np_utils.to_categorical(y_test,10)\n",
        "\n",
        "print(\"train data shape \",X_train.shape)\n",
        "print(\"test data shape \",X_test.shape)\n",
        "print(\"output train labels shape \",y_train.shape)\n",
        "print(\"output test labels shape \",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape  (60000, 28, 28, 1)\n",
            "test data shape  (10000, 28, 28, 1)\n",
            "output train labels shape  (60000, 10)\n",
            "output test labels shape  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv85P0H1QTcO"
      },
      "source": [
        "batch_size=100\n",
        "epoches=10\n",
        "num_classes=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MCLno3Z2A6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RppijaG0tzHg"
      },
      "source": [
        "## ASSIGNMENT-14 (CNN ON MNIST DATA)\n",
        "\n",
        "***key points:***\n",
        "\n",
        "*   for each dense layers we have considered batch normalization and dropout rate of 0.4 as our results obtained in assignment-13.\n",
        "\n",
        "*  In this assignment all the observations are done stepwise as:\n",
        "\n",
        "\n",
        "1.   Changing the feature maps.\n",
        "2.   Changing the kernel size.\n",
        "3.   Changing the padding.\n",
        "4.   With maxpooling and without maxpooling.\n",
        "5.   With average pooling and without average pooling.\n",
        "6.   Changing pool_size.\n",
        "7.   Changing the number of dense layers.\n",
        "8.   Affect of batch normalization on convolution layers.\n",
        "9.   Affect of dropout on convolution layers.\n",
        "10.   Affect of data augmentation.\n",
        "\n",
        "*  In each succesive step the best best value we got we incorporate that value for the next steps.\n",
        "\n",
        "* As for 7 convolution layers the computation is more So only 1 example of 7 convolution layers is depicted in the assignment.\n",
        "\n",
        "* As Due to computaion issues the number of epochs are kept 10.\n",
        "\n",
        "* For the pool_strides it has been kept (1,1) as we don't want to reduce our 28x28 matrix to almost 0 dimensions as it is feeded to deeper CNNs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFvN0_Jk6QPn"
      },
      "source": [
        "## [0].Some Common Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKP2RyjP4zqw"
      },
      "source": [
        "**0.1 Plotting the loss  and accuracy graph vs number of epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEqsLEfQZAgp"
      },
      "source": [
        "def plot_graph(history,model):\n",
        "  print(\"test log-loss \",model.evaluate(X_test,y_test,verbose=0)[0])\n",
        "  print(\"test accuracy \",model.evaluate(X_test,y_test,verbose=0)[1])\n",
        "  plt.figure(figsize=(16,6))\n",
        "  for i in range(1,3):\n",
        "    plt.subplot(1,2,i)\n",
        "    plt.grid()\n",
        "    if i==1:\n",
        "      plt.plot(np.arange(1,epoches+1),history.history['loss'],label=\"Train Loss\")\n",
        "      plt.plot(np.arange(1,epoches+1),history.history['val_loss'],label=\"Test Loss\")\n",
        "      plt.ylabel(\"cross entropy loss\")\n",
        "    else:\n",
        "      plt.plot(np.arange(1,epoches+1),history.history['acc'],label=\"Train Accuracy\")\n",
        "      plt.plot(np.arange(1,epoches+1),history.history['val_acc'],label=\"Test Accuracy\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"number of epochs\")\n",
        "    \n",
        "    plt.legend()\n",
        "  plt.suptitle(\"Error Plots\")\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrmE5o76XCo"
      },
      "source": [
        "**0.2 Misclassified point samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCsqeyuO6Zzx"
      },
      "source": [
        "#http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html\n",
        "def misclassified_pts(model):\n",
        "  print(\"Fraction of missclassified points \\n\",np.round(1-model2.evaluate(X_test,y_test,verbose=0)[1],3))\n",
        "  print(\"Some Samples Of missclassified Points\\n\")\n",
        "  y_pred=model.predict_classes(X_test)\n",
        "\n",
        "  misclf_pts=[im for im in zip(X_test,np.argmax(y_test,axis=1),y_pred) if im[1]!=im[2]]\n",
        "\n",
        "  plt.figure(figsize=(10,6))\n",
        "\n",
        "  for idx,val in enumerate(misclf_pts[:25]):\n",
        "    plt.subplots_adjust(left=0,right=1,top=1,bottom=0)\n",
        "    #as matplotlib gives black for a low pixel value\n",
        "    plt.subplot(5,5,idx+1)\n",
        "    imag=1-val[0].reshape((28,28))\n",
        "    plt.axis('off')\n",
        "    plt.text(0,0,val[1],color='black')\n",
        "    plt.text(0,10,val[2],color='red')\n",
        "    plt.imshow(imag,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk5fJQVtZHRc"
      },
      "source": [
        "**0.3 Getting images after data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LKra_eZGE8"
      },
      "source": [
        "#https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
        "#https://www.kaggle.com/gimunu/data-augmentation-with-keras-into-cnn\n",
        "\n",
        "def show_samples_of_augmented_images(datagen):\n",
        "  print(\"Some samples after performing data augmentation\")\n",
        "  \n",
        "  #it will return images in batches of 32\n",
        "  imga,_=next(datagen.flow(X_train,y_train,batch_size=32))\n",
        "  plt.figure(figsize=(10,6))\n",
        "\n",
        "  for i in np.arange(32):\n",
        "    plt.subplots_adjust(left=0,right=1,top=1,bottom=0)\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.imshow(1-imga[i].reshape(28,28),cmap='gray')\n",
        "    plt.xticks([],[])\n",
        "    plt.yticks([],[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHUBnzCgZ3p8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRiUv_0KMZQA"
      },
      "source": [
        "## [1] Common Function For creating model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMo8Q26sMhQd"
      },
      "source": [
        "def create_model(nu_conv_layers,kernel_size,kernel_strides,padding,feature_maps,augmentation_done,max_pooling,avg_pooling,pool_size,pool_strides,dropout,\n",
        "                 nu_dense_lyrs,size_dense_layers,BN):\n",
        "  model=Sequential()\n",
        "  \n",
        "  \n",
        "  \n",
        "  #defining the initial layer\n",
        "  \n",
        "  model.add(Conv2D(filters=feature_maps[0],activation='relu',kernel_size=kernel_size,strides=kernel_strides,padding=padding,\\\n",
        "                   input_shape=input_shape,kernel_initializer=glorot_uniform()))\n",
        "  if max_pooling[0]:\n",
        "    model.add(MaxPooling2D(pool_size=pool_size,strides=pool_strides[0]))\n",
        "  if avg_pooling[0]:\n",
        "    model.add(AveragePooling2D(pool_size=pool_size,strides=pool_strides[0]))\n",
        "  if BN[0]:\n",
        "    model.add(BatchNormalization())\n",
        "  if dropout[0]:\n",
        "    model.add(Dropout(dropout[1])) \n",
        "  \n",
        "  #creating intermediate layers\n",
        "  \n",
        "  for layer in range(1,nu_conv_layers):\n",
        "      model.add(Conv2D(filters=feature_maps[layer],activation='relu',kernel_size=kernel_size,strides=kernel_strides,\\\n",
        "                       padding=padding,kernel_initializer=glorot_uniform()))\n",
        "      \n",
        "      if max_pooling[layer]:\n",
        "        model.add(MaxPooling2D(pool_size=pool_size,strides=pool_strides[layer]))\n",
        "      if avg_pooling[layer]:\n",
        "        model.add(AveragePooling2D(pool_size=pool_size,strides=pool_strides[layer]))\n",
        "      if BN[layer]:\n",
        "        model.add(BatchNormalization())\n",
        "      if dropout[0]:\n",
        "        model.add(Dropout(dropout[1])) \n",
        "      \n",
        "   \n",
        "  model.add(Flatten())\n",
        "  \n",
        "  #adding the dense layers\n",
        "  for dn_lyr in range(nu_dense_lyrs):\n",
        "    model.add(Dense(size_dense_layers[dn_lyr],activation='relu',kernel_initializer=glorot_uniform()))\n",
        "  #as we know adding batch normalization to dense layers always produce god result so we will use BN + dropout in the dense layers  \n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    \n",
        "  #adding the final softmax layer\n",
        "  \n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "  \n",
        "  \n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  #if data augmentation is performed then we are are returning the ImageDataGenerator instance also\n",
        "  #as our data is mnist we will avoid the parameters like horizontal flip ,vertical flip ,rotation of image more than 90 etc.\n",
        "  #We will use the transformation that will not affect our meaning of dataset.\n",
        "  \n",
        "  if augmentation_done :\n",
        "    datagen=ImageDataGenerator(width_shift_range=0.2,height_shift_range=0.2,rotation_range=30,shear_range=12,horizontal_flip=False,vertical_flip=False)\n",
        "\n",
        "    #fiiting our train data to imagedata_augmentor\n",
        "\n",
        "    datagen.fit(X_train,augment=True)\n",
        "    \n",
        "    history=model.fit_generator(datagen.flow(X_train,y_train,batch_size=batch_size),epochs=epoches,\\\n",
        "                                steps_per_epoch=X_train.shape[0]/batch_size,verbose=1,validation_data=(X_test,y_test))\n",
        "    \n",
        "    return history,model,datagen\n",
        "  \n",
        "  else :\n",
        "    history=model.fit(X_train,y_train,verbose=1,epochs=epoches,batch_size=batch_size,validation_data=(X_test,y_test))\n",
        "  \n",
        "    return history,model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6T-DOCYmo7R"
      },
      "source": [
        "## [2] Changing Different Parameters On The MNIST Dataset\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFISQ3-YWgC"
      },
      "source": [
        "**[2.1] affect of changing the feature maps (number of filters)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "hSzbFd41cZEI",
        "outputId": "ec48aaf3-d72e-42ba-e025-9c34c129fecf"
      },
      "source": [
        "history51,model51=create_model(nu_conv_layers=2,kernel_size=5,kernel_strides=(2,2),padding='same',feature_maps=[8,16],augmentation_done=False,\n",
        "                               max_pooling=[False]*2,avg_pooling=[False]*2,pool_size=(2,2),pool_strides=[(1,1)]*2,dropout=[False,0.4],\n",
        "                               nu_dense_lyrs=1,size_dense_layers=[128],BN=[True]*2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 21s 343us/step - loss: 0.2529 - acc: 0.9235 - val_loss: 0.0757 - val_acc: 0.9750\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 19s 319us/step - loss: 0.0881 - acc: 0.9726 - val_loss: 0.0549 - val_acc: 0.9826\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 19s 311us/step - loss: 0.0639 - acc: 0.9800 - val_loss: 0.0444 - val_acc: 0.9844\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 19s 311us/step - loss: 0.0496 - acc: 0.9848 - val_loss: 0.0378 - val_acc: 0.9885\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 19s 309us/step - loss: 0.0436 - acc: 0.9859 - val_loss: 0.0440 - val_acc: 0.9854\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 19s 311us/step - loss: 0.0377 - acc: 0.9880 - val_loss: 0.0382 - val_acc: 0.9880\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 19s 311us/step - loss: 0.0307 - acc: 0.9903 - val_loss: 0.0365 - val_acc: 0.9876\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 19s 311us/step - loss: 0.0264 - acc: 0.9911 - val_loss: 0.0327 - val_acc: 0.9887\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 19s 314us/step - loss: 0.0258 - acc: 0.9913 - val_loss: 0.0390 - val_acc: 0.9876\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 19s 310us/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0383 - val_acc: 0.9884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "2CNlfLs6pNgz",
        "outputId": "4ce6907e-56c6-4e65-aaba-003877fef544"
      },
      "source": [
        "history52,model52=create_model(nu_conv_layers=2,kernel_size=5,kernel_strides=(2,2),padding='same',feature_maps=[2,2],augmentation_done=False,\n",
        "                               max_pooling=[False]*2,avg_pooling=[False]*2,pool_size=(2,2),pool_strides=[(1,1)]*2,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.5811 - acc: 0.8188 - val_loss: 0.1767 - val_acc: 0.9446\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.2042 - acc: 0.9373 - val_loss: 0.1180 - val_acc: 0.9625\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.1589 - acc: 0.9517 - val_loss: 0.1011 - val_acc: 0.9683\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1379 - acc: 0.9583 - val_loss: 0.0931 - val_acc: 0.9686\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1291 - acc: 0.9601 - val_loss: 0.0900 - val_acc: 0.9718\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1169 - acc: 0.9642 - val_loss: 0.0863 - val_acc: 0.9710\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.1125 - acc: 0.9657 - val_loss: 0.0902 - val_acc: 0.9702\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1080 - acc: 0.9667 - val_loss: 0.0765 - val_acc: 0.9750\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1012 - acc: 0.9693 - val_loss: 0.0720 - val_acc: 0.9774\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1001 - acc: 0.9691 - val_loss: 0.0678 - val_acc: 0.9774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "g9Br_OzppjHA",
        "outputId": "d1305cd0-b2fc-4a8e-de40-d1f5eb69a574"
      },
      "source": [
        "history53,model53=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='same',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 267s 4ms/step - loss: 0.1223 - acc: 0.9638 - val_loss: 0.0543 - val_acc: 0.9831\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 268s 4ms/step - loss: 0.0466 - acc: 0.9862 - val_loss: 0.0365 - val_acc: 0.9878\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 267s 4ms/step - loss: 0.0324 - acc: 0.9901 - val_loss: 0.0280 - val_acc: 0.9904\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0243 - acc: 0.9921 - val_loss: 0.0297 - val_acc: 0.9899\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0474 - val_acc: 0.9860\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0381 - val_acc: 0.9877\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0309 - val_acc: 0.9910\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0304 - val_acc: 0.9912\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9909\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 263s 4ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0313 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZCR_g-OfpvRt",
        "outputId": "a9afd5c5-0b05-4cc8-8a4e-a1572eaf3fb9"
      },
      "source": [
        "history54,model54=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(2,2),padding='same',feature_maps=[4,4,4],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.5130 - acc: 0.8362 - val_loss: 0.1787 - val_acc: 0.9418\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1973 - acc: 0.9404 - val_loss: 0.1120 - val_acc: 0.9666\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.1444 - acc: 0.9557 - val_loss: 0.1061 - val_acc: 0.9659\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1206 - acc: 0.9636 - val_loss: 0.0794 - val_acc: 0.9736\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.1091 - acc: 0.9667 - val_loss: 0.0750 - val_acc: 0.9764\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0990 - acc: 0.9694 - val_loss: 0.0751 - val_acc: 0.9760\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0914 - acc: 0.9719 - val_loss: 0.0778 - val_acc: 0.9745\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0857 - acc: 0.9734 - val_loss: 0.0654 - val_acc: 0.9794\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0831 - acc: 0.9744 - val_loss: 0.0583 - val_acc: 0.9823\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0770 - acc: 0.9757 - val_loss: 0.0602 - val_acc: 0.9805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfglXQfcNRpw"
      },
      "source": [
        "**[2.1.1] Effect Of Using Different Number Of Kernels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "aqIx8IWDNRCf",
        "outputId": "5e76046b-8cd5-4abc-d1c4-7ad1d8ed2464"
      },
      "source": [
        "pt_fm=PrettyTable()\n",
        "pt_fm.field_names=[\"conv2D layers\",\"nu_filters\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_fm.add_row([2,\"8 || 16\",np.round(history51.history['loss'][9],3),\n",
        "               np.round(model51.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model51.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "               \n",
        "pt_fm.add_row([2,\"2 ||2\",np.round(history52.history['loss'][9],3),\n",
        "               np.round(model52.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model52.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "               \n",
        "pt_fm.add_row([3,\"8||16||32\",np.round(history53.history['loss'][9],3),\n",
        "               np.round(model53.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model53.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "               \n",
        "pt_fm.add_row([3,\"4||4||4\",np.round(history54.history['loss'][9],3),\n",
        "               np.round(model54.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model54.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "print(\"effect of number of filters on cnn performance keeping other parameters same\")\n",
        "print(pt_fm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of number of filters on cnn performance keeping other parameters same\n",
            "+---------------+------------+------------+-----------+---------------+\n",
            "| conv2D layers | nu_filters | train loss | test loss | test accuracy |\n",
            "+---------------+------------+------------+-----------+---------------+\n",
            "|       2       |  8 || 16   |   0.024    |   0.038   |     0.988     |\n",
            "|       2       |   2 ||2    |    0.1     |   0.068   |     0.977     |\n",
            "|       3       | 8||16||32  |    0.01    |   0.031   |     0.991     |\n",
            "|       3       |  4||4||4   |   0.077    |    0.06   |      0.98     |\n",
            "+---------------+------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1dF-OF-cxZZ"
      },
      "source": [
        "***CONCLUSIONS***\n",
        "\n",
        "\n",
        "*   The number of feature maps should considerable increase for later layers as initial layers are just to detect edges and later layers are used to detect the  little details from an image.So the more number of feature maps we have the more details we have.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yu67RNbYhwc"
      },
      "source": [
        "**[3.2] affect of the kernel_size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RZf2ilnx4Kj"
      },
      "source": [
        "#(7,7)\n",
        "history55,model55=create_model(nu_conv_layers=3,kernel_size=7,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "tObAMpYayOS8",
        "outputId": "c8ee45e6-a97d-4e6d-9846-7ada96a2ec63"
      },
      "source": [
        "#(3,3)\n",
        "history56,model56=create_model(nu_conv_layers=3,kernel_size=3,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.1411 - acc: 0.9580 - val_loss: 0.1191 - val_acc: 0.9657\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0564 - acc: 0.9831 - val_loss: 0.0487 - val_acc: 0.9836\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0410 - acc: 0.9877 - val_loss: 0.0466 - val_acc: 0.9845\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0308 - acc: 0.9903 - val_loss: 0.0533 - val_acc: 0.9844\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0242 - acc: 0.9923 - val_loss: 0.0320 - val_acc: 0.9892\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0342 - val_acc: 0.9890\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0160 - acc: 0.9949 - val_loss: 0.0365 - val_acc: 0.9888\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0347 - val_acc: 0.9891\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0126 - acc: 0.9954 - val_loss: 0.0384 - val_acc: 0.9880\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0407 - val_acc: 0.9894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "X3rmrLGhx-gG",
        "outputId": "d56c8653-7c6a-4604-b86c-7eff26e4999c"
      },
      "source": [
        "history539,model539=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.1305 - acc: 0.9616 - val_loss: 0.0450 - val_acc: 0.9851\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0505 - acc: 0.9851 - val_loss: 0.0698 - val_acc: 0.9771\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0352 - val_acc: 0.9869\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0285 - acc: 0.9915 - val_loss: 0.0322 - val_acc: 0.9897\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.0359 - val_acc: 0.9894\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0286 - val_acc: 0.9906\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0156 - acc: 0.9954 - val_loss: 0.0342 - val_acc: 0.9901\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0321 - val_acc: 0.9891\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0324 - val_acc: 0.9907\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0283 - val_acc: 0.9916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZH3xY-YLLp4"
      },
      "source": [
        "**[3.2.1] comparing  on kernel sizes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "df-KzClNLQSd",
        "outputId": "05a383f3-ec23-45f7-fa1f-5bd7dbee4994"
      },
      "source": [
        "pt_ks=PrettyTable()\n",
        "pt_ks.field_names=[\"conv_layers\",\"kernels size used\",\"padding\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "\n",
        "pt_ks.add_row([3,(3,3),'valid',np.round(history56.history['loss'][9],3),\n",
        "               np.round(model56.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model56.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ks.add_row([3,(5,5),'valid',np.round(history539.history['loss'][9],3),\n",
        "               np.round(model539.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model539.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ks.add_row([3,(7,7),'valid',np.round(history55.history['loss'][9],3),\n",
        "               np.round(model55.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model55.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "print(\"Affect Of Kernel Sizes On Test loss And Accuracy keeping other parameters same\")\n",
        "print(pt_ks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Affect Of Kernel Sizes On Test loss And Accuracy keeping other parameters same\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n",
            "| conv_layers | kernels size used | padding | train loss | test loss | test accuracy |\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n",
            "|      3      |       (3, 3)      |  valid  |   0.009    |   0.041   |     0.989     |\n",
            "|      3      |       (5, 5)      |  valid  |   0.013    |   0.028   |     0.992     |\n",
            "|      3      |       (7, 7)      |  valid  |   0.021    |   0.029   |     0.991     |\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZnaLRF49poi"
      },
      "source": [
        "***CONCLUSIONS***\n",
        "\n",
        "\n",
        "*  kernel should be kept of size medium (5,5).As having too small kernels will include extra informations/pixels and large kernels will skip the important pixel/edge features.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTGkajbMN__u"
      },
      "source": [
        "**[3.3] affect of padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "bno3k8eqODX7",
        "outputId": "08e0f8e6-5dac-4214-a3e9-6bffdfcc3f45"
      },
      "source": [
        "#here we have to keep in mind that we should carefully choose the number of layers and kernel size such that our original dimensions do not vanish\n",
        "history561,model561=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 103s 2ms/step - loss: 0.1253 - acc: 0.9636 - val_loss: 0.0408 - val_acc: 0.9875\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0472 - acc: 0.9860 - val_loss: 0.0281 - val_acc: 0.9907\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0362 - acc: 0.9889 - val_loss: 0.0413 - val_acc: 0.9864\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0322 - val_acc: 0.9896\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0300 - val_acc: 0.9906\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0342 - val_acc: 0.9889\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0296 - val_acc: 0.9918\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.0287 - val_acc: 0.9915\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0114 - acc: 0.9962 - val_loss: 0.0367 - val_acc: 0.9901\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.0316 - val_acc: 0.9901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXY77PzsQvFT"
      },
      "source": [
        "**[3.3.1] summarizing the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "gOkm2ToiQuXQ",
        "outputId": "9d3d585d-af17-45d3-b79c-78efbf766a06"
      },
      "source": [
        "pt_pd=PrettyTable()\n",
        "pt_pd.field_names=[\"conv_layers\",\"kernel size\",\"padding\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_pd.add_row([3,(5,5),'valid',np.round(history561.history['loss'][9],3),\n",
        "               np.round(model561.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model561.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_pd.add_row([3,(5,5),'same',np.round(history53.history['loss'][9],3),\n",
        "               np.round(model53.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model53.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "print(\"Affect Of padding On Test loss And Accuracy keeping other parameters same\")\n",
        "print(pt_pd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Affect Of padding On Test loss And Accuracy keeping other parameters same\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n",
            "| conv_layers | kernel size | padding | train loss | test loss | test accuracy |\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n",
            "|      3      |    (5, 5)   |  valid  |   0.011    |   0.032   |      0.99     |\n",
            "|      3      |    (5, 5)   |   same  |    0.01    |   0.031   |     0.991     |\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53WLJLrE_A5x"
      },
      "source": [
        "***CONCLUSION***\n",
        "\n",
        "\n",
        "*   padding='valid' is better option in place of 'same' untill and unless our original matrix do not vanishes before last layer.\n",
        "* padding='same' is used commonly if somehow due to succesive convolution and maxpool operations the matrix vanishes.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nasmmV2qYu1t"
      },
      "source": [
        "**[3.4] affect of adding maxpooling layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dRhKA0nyryh"
      },
      "source": [
        "#adding maxpool everywhere\n",
        "history57,model57=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[True]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-V_BBSc0SxYb",
        "outputId": "971785c6-5edf-4d0d-fb43-c6421b43f596"
      },
      "source": [
        "#without maxpooling on 5 convolution layer architecture\n",
        "history58,model58=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,40],augmentation_done=False,\n",
        "                               max_pooling=[False]*5,avg_pooling=[False]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.1676 - acc: 0.9504 - val_loss: 0.0727 - val_acc: 0.9768\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0599 - acc: 0.9819 - val_loss: 0.0374 - val_acc: 0.9879\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0484 - acc: 0.9857 - val_loss: 0.0674 - val_acc: 0.9784\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0381 - acc: 0.9883 - val_loss: 0.0413 - val_acc: 0.9877\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0358 - acc: 0.9892 - val_loss: 0.0349 - val_acc: 0.9894\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 152s 3ms/step - loss: 0.0299 - acc: 0.9912 - val_loss: 0.0259 - val_acc: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0268 - acc: 0.9918 - val_loss: 0.0264 - val_acc: 0.9925\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0356 - val_acc: 0.9893\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0307 - val_acc: 0.9905\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0286 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "o5vA-SpoSyg7",
        "outputId": "1423ed71-cebb-42b8-835e-41418a97f203"
      },
      "source": [
        "#with maxpooling on 5 conv layer(EVERYWHERE)\n",
        "history59,model59=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,40],augmentation_done=False,\n",
        "                               max_pooling=[True]*5,avg_pooling=[False]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.2038 - acc: 0.9387 - val_loss: 0.1501 - val_acc: 0.9527\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0770 - acc: 0.9771 - val_loss: 0.0785 - val_acc: 0.9745\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0593 - acc: 0.9818 - val_loss: 0.0816 - val_acc: 0.9714\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0502 - acc: 0.9849 - val_loss: 0.0768 - val_acc: 0.9753\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0445 - acc: 0.9863 - val_loss: 0.0403 - val_acc: 0.9865\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0412 - acc: 0.9872 - val_loss: 0.0401 - val_acc: 0.9874\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0642 - val_acc: 0.9798\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0343 - acc: 0.9894 - val_loss: 0.0379 - val_acc: 0.9880\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0369 - val_acc: 0.9887\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0291 - acc: 0.9905 - val_loss: 0.0437 - val_acc: 0.9863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "2VIVMe6fS0qX",
        "outputId": "81e6bcac-e2a4-44ae-f7bb-3033193120b1"
      },
      "source": [
        "#with maxpooling on 5 conv layer(INITIAL LAYERS ONLY)\n",
        "history5_1,model5_1=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,40],augmentation_done=False,\n",
        "                               max_pooling=[True,True,True,False,False],avg_pooling=[False]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,\n",
        "                                 dropout=[False,0.4],nu_dense_lyrs=1,size_dense_layers=[128],BN=[False]*5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1795 - acc: 0.9461 - val_loss: 0.0847 - val_acc: 0.9752\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0704 - acc: 0.9789 - val_loss: 0.0615 - val_acc: 0.9811\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0542 - acc: 0.9842 - val_loss: 0.0436 - val_acc: 0.9865\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0458 - acc: 0.9862 - val_loss: 0.0470 - val_acc: 0.9854\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0419 - acc: 0.9878 - val_loss: 0.0529 - val_acc: 0.9842\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0380 - acc: 0.9883 - val_loss: 0.0302 - val_acc: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0324 - acc: 0.9899 - val_loss: 0.0288 - val_acc: 0.9920\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0290 - acc: 0.9907 - val_loss: 0.0320 - val_acc: 0.9903\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0280 - acc: 0.9912 - val_loss: 0.0292 - val_acc: 0.9909\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0380 - val_acc: 0.9888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jrVe47pRk34"
      },
      "source": [
        "**[3.4.1] summarizing results obtained**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "s2QSoMK9RqLN",
        "outputId": "85ac733b-c80e-41a2-9b30-1470bd9e1397"
      },
      "source": [
        "pt_mp=PrettyTable()\n",
        "pt_mp.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"max_pooling\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_mp.add_row([3,\"(5,5)\",'valid',\"0--0--0\",np.round(history561.history['loss'][9],3),\n",
        "              np.round(model561.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model561.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_mp.add_row([3,\"(5,5)\",'valid',\"1--1--1\",np.round(history57.history['loss'][9],3),\n",
        "              np.round(model57.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model57.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_mp.add_row([5,\"(5,5)\",'valid',\"0-0-0-0-0\",np.round(history58.history['loss'][9],3),\n",
        "              np.round(model58.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model58.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_mp.add_row([5,\"(5,5)\",'valid',\"1-1-1-0-0\",np.round(history5_1.history['loss'][9],3),\n",
        "              np.round(model5_1.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_1.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_mp.add_row([5,\"(5,5)\",'valid',\"1-1-1-1-1\",np.round(history59.history['loss'][9],3),\n",
        "              np.round(model59.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model59.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "print(\"effect of maxpool layer on cnn performance keeping other parameters same\")\n",
        "print(pt_mp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of maxpool layer on cnn performance keeping other parameters same\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | max_pooling | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |   0--0--0   |   0.011    |   0.032   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |   1--1--1   |   0.019    |   0.022   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |  0-0-0-0-0  |    0.02    |   0.029   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |  1-1-1-0-0  |   0.026    |   0.038   |     0.989     |\n",
            "|       5       | (5,5)  |  valid  |  1-1-1-1-1  |   0.029    |   0.044   |     0.986     |\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7We8pbAJR8R"
      },
      "source": [
        "***CONCLUSIONS***\n",
        "\n",
        "\n",
        "*   maxpool is used for location invariance of objects in an image.As we have simple mnist data so that maybe the reason maxpool is not working that much good here because all we have is 1 object in given image(i.e the number)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJ9oLwXO_MD"
      },
      "source": [
        "**[3.5] Using Average Pooling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOx9wpvgPEUU"
      },
      "source": [
        "#with average pooling on 3 layers\n",
        "history5611,model5611=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[True]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "CI_fFAQaQBaV",
        "outputId": "c2804dcb-da11-49fc-d494-4c8fb3aa2c57"
      },
      "source": [
        "#with average pooling on 5 layers\n",
        "history581,model581=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,40],augmentation_done=False,\n",
        "                               max_pooling=[False]*5,avg_pooling=[True]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 0.2113 - acc: 0.9352 - val_loss: 0.1385 - val_acc: 0.9576\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0785 - acc: 0.9769 - val_loss: 0.0680 - val_acc: 0.9775\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0609 - acc: 0.9820 - val_loss: 0.0486 - val_acc: 0.9844\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0528 - acc: 0.9842 - val_loss: 0.0464 - val_acc: 0.9853\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0453 - acc: 0.9860 - val_loss: 0.0360 - val_acc: 0.9890\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0410 - acc: 0.9875 - val_loss: 0.0324 - val_acc: 0.9890\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0368 - acc: 0.9888 - val_loss: 0.0506 - val_acc: 0.9862\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0341 - acc: 0.9892 - val_loss: 0.0434 - val_acc: 0.9865\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.0371 - val_acc: 0.9891\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0297 - acc: 0.9908 - val_loss: 0.0346 - val_acc: 0.9897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAZ_Ve2RuW7Y"
      },
      "source": [
        "**[3.5.1] Summarizing the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "i7G3zFq0Tdhm",
        "outputId": "5f2a7300-e748-4b98-f9d9-993440f72069"
      },
      "source": [
        "pt_ap=PrettyTable()\n",
        "pt_ap.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"avg_pooling?\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_ap.add_row([3,\"(5,5)\",'valid',\"No\",np.round(history561.history['loss'][9],3),\n",
        "              np.round(model561.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model561.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ap.add_row([3,\"(5,5)\",'valid',\"Yes\",np.round(history5611.history['loss'][9],3),\n",
        "              np.round(model5611.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5611.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ap.add_row([5,\"(5,5)\",'valid',\"No\",np.round(history58.history['loss'][9],3),\n",
        "              np.round(model58.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model58.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ap.add_row([5,\"(5,5)\",'valid',\"Yes\",np.round(history581.history['loss'][9],3),\n",
        "              np.round(model581.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model581.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "print(pt_ap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | avg_pooling? | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |      No      |   0.011    |   0.032   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |     Yes      |    0.02    |   0.023   |     0.993     |\n",
            "|       5       | (5,5)  |  valid  |      No      |    0.02    |   0.029   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |     Yes      |    0.03    |   0.035   |      0.99     |\n",
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KnwYqyhqHHJ"
      },
      "source": [
        "* average pooling working slightly better than maxpooling but still the results are better if we don't use any pooling methods.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwZZDHm_Zt2J"
      },
      "source": [
        "**[3.6] Affect of adding different pool_size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "g87YL8JXRq9P",
        "outputId": "dc24d275-97cd-483e-dbec-6e088524f6eb"
      },
      "source": [
        "#(4,4)  pool_size\n",
        "history5_2,model5_2=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(4,4),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 110s 2ms/step - loss: 0.1283 - acc: 0.9627 - val_loss: 0.0480 - val_acc: 0.9841\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0509 - acc: 0.9848 - val_loss: 0.0439 - val_acc: 0.9861\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0364 - acc: 0.9889 - val_loss: 0.0364 - val_acc: 0.9886\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0284 - acc: 0.9913 - val_loss: 0.0367 - val_acc: 0.9890\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0279 - val_acc: 0.9891\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0203 - acc: 0.9932 - val_loss: 0.0286 - val_acc: 0.9911\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0200 - val_acc: 0.9937\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0264 - val_acc: 0.9917\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0304 - val_acc: 0.9909\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0296 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "BNEjLqnVKoHU",
        "outputId": "95f3909c-c8c0-408f-e61f-b8bdc1b023c8"
      },
      "source": [
        "#(6,6)\n",
        "history5_3,model5_3=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(6,6),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=1,\n",
        "                               size_dense_layers=[128],BN=[False]*3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 109s 2ms/step - loss: 0.1235 - acc: 0.9632 - val_loss: 0.0478 - val_acc: 0.9844\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0474 - acc: 0.9851 - val_loss: 0.0383 - val_acc: 0.9874\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0409 - val_acc: 0.9879\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.0556 - val_acc: 0.9822\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.0318 - val_acc: 0.9905\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0308 - val_acc: 0.9905\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0159 - acc: 0.9950 - val_loss: 0.0362 - val_acc: 0.9901\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0290 - val_acc: 0.9904\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0272 - val_acc: 0.9920\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0274 - val_acc: 0.9914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZsuPyGPSlhD"
      },
      "source": [
        "**[3.6.1] summarizing the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "t1FvwAtUSkdt",
        "outputId": "42dc6e76-b5ac-441d-e63a-287a2c492c7f"
      },
      "source": [
        "pt_ps=PrettyTable()\n",
        "pt_ps.field_names=[\"conv2D layers\",\"kernel size\",\"padding\",\"maxpool/avgpool?\",\"poolsize\",\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_ps.add_row([3,\"(5,5)\",\"valid\",'NO',(2,2),np.round(history57.history['loss'][9],3),\n",
        "              np.round(model561.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model561.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ps.add_row([3,\"(5,5)\",\"valid\",'No',(4,4),np.round(history5_2.history['loss'][9],3),\n",
        "              np.round(model5_2.evaluate(X_test,y_test,verbose=0)[0],2),np.round(model5_2.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_ps.add_row([3,\"(5,5)\",\"valid\",'No',(6,6),np.round(history5_3.history['loss'][9],3),\n",
        "              np.round(model5_3.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_3.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "print(\"effect of different pool size on cnn performance keeping other parameters same\")\n",
        "print(pt_ps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of different pool size on cnn performance keeping other parameters same\n",
            "+---------------+-------------+---------+------------------+----------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel size | padding | maxpool/avgpool? | poolsize | train loss | test loss | test accuracy |\n",
            "+---------------+-------------+---------+------------------+----------+------------+-----------+---------------+\n",
            "|       3       |    (5,5)    |  valid  |        NO        |  (2, 2)  |   0.019    |   0.032   |      0.99     |\n",
            "|       3       |    (5,5)    |  valid  |        No        |  (4, 4)  |   0.011    |    0.03   |     0.992     |\n",
            "|       3       |    (5,5)    |  valid  |        No        |  (6, 6)  |    0.01    |   0.027   |     0.991     |\n",
            "+---------------+-------------+---------+------------------+----------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OogP7KNzXQQD"
      },
      "source": [
        "**[3.7] effect of adding more number of dense layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "gmG7PVPYXPjL",
        "outputId": "c6c57670-672e-4f5a-de4f-5a52713065fb"
      },
      "source": [
        "history5_4,model5_4=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=2,\n",
        "                               size_dense_layers=[32,16],BN=[False]*3)\n",
        "\n",
        "history5_5,model5_5=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=3,\n",
        "                               size_dense_layers=[64,32,16],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.7039 - acc: 0.7966 - val_loss: 0.0741 - val_acc: 0.9787\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 94s 2ms/step - loss: 0.2690 - acc: 0.9232 - val_loss: 0.0498 - val_acc: 0.9848\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 95s 2ms/step - loss: 0.1976 - acc: 0.9425 - val_loss: 0.0566 - val_acc: 0.9833\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 93s 2ms/step - loss: 0.1678 - acc: 0.9502 - val_loss: 0.0385 - val_acc: 0.9878\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 92s 2ms/step - loss: 0.1412 - acc: 0.9574 - val_loss: 0.0428 - val_acc: 0.9870\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 92s 2ms/step - loss: 0.1369 - acc: 0.9572 - val_loss: 0.0365 - val_acc: 0.9896\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 93s 2ms/step - loss: 0.1195 - acc: 0.9630 - val_loss: 0.0330 - val_acc: 0.9903\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 94s 2ms/step - loss: 0.1156 - acc: 0.9643 - val_loss: 0.0346 - val_acc: 0.9906\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 94s 2ms/step - loss: 0.1056 - acc: 0.9655 - val_loss: 0.0409 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 94s 2ms/step - loss: 0.1046 - acc: 0.9660 - val_loss: 0.0382 - val_acc: 0.9899\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 102s 2ms/step - loss: 0.8834 - acc: 0.7331 - val_loss: 0.0890 - val_acc: 0.9777\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.3197 - acc: 0.9115 - val_loss: 0.0727 - val_acc: 0.9803\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.2156 - acc: 0.9426 - val_loss: 0.0658 - val_acc: 0.9818\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1738 - acc: 0.9534 - val_loss: 0.0450 - val_acc: 0.9884\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1430 - acc: 0.9614 - val_loss: 0.0474 - val_acc: 0.9858\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1341 - acc: 0.9644 - val_loss: 0.0700 - val_acc: 0.9838\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1235 - acc: 0.9669 - val_loss: 0.0319 - val_acc: 0.9921\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1081 - acc: 0.9713 - val_loss: 0.0316 - val_acc: 0.9917\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1009 - acc: 0.9726 - val_loss: 0.0296 - val_acc: 0.9929\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0959 - acc: 0.9738 - val_loss: 0.0421 - val_acc: 0.9898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "SW8eVZpv8yq6",
        "outputId": "8deb4c45-2336-405f-967f-64a6eb53f858"
      },
      "source": [
        "history5_5_1,model5_5_1=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=3,\n",
        "                               size_dense_layers=[64,32,16,8],BN=[False]*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 103s 2ms/step - loss: 0.8434 - acc: 0.7410 - val_loss: 0.0888 - val_acc: 0.9773\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.3087 - acc: 0.9148 - val_loss: 0.0484 - val_acc: 0.9846\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.2158 - acc: 0.9408 - val_loss: 0.0378 - val_acc: 0.9886\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1661 - acc: 0.9553 - val_loss: 0.0392 - val_acc: 0.9888\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1480 - acc: 0.9600 - val_loss: 0.0447 - val_acc: 0.9874\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1316 - acc: 0.9646 - val_loss: 0.0340 - val_acc: 0.9912\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1228 - acc: 0.9680 - val_loss: 0.0310 - val_acc: 0.9919\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1083 - acc: 0.9708 - val_loss: 0.0506 - val_acc: 0.9887\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 100s 2ms/step - loss: 0.1007 - acc: 0.9729 - val_loss: 0.0330 - val_acc: 0.9914\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0949 - acc: 0.9735 - val_loss: 0.0303 - val_acc: 0.9921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URsKcYovInUY"
      },
      "source": [
        "**[3.7.1] summarizing the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "zrdlO0XkIq3K",
        "outputId": "384b9a48-a215-4e48-e52a-6810702a0145"
      },
      "source": [
        "pt_dl=PrettyTable()\n",
        "pt_dl.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"maxpool/avgpool?\",\"poolsize\",\"num_dense_layers\",\"train_loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_dl.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",1,np.round(history57.history['loss'][9],3),\n",
        "              np.round(model57.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model57.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dl.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",2,np.round(history5_4.history['loss'][9],3),\n",
        "              np.round(model5_4.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_4.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dl.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,np.round(history5_5.history['loss'][9],3),\n",
        "              np.round(model5_5.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_5.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dl.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",4,np.round(history5_5_1.history['loss'][9],3),\n",
        "              np.round(model5_5_1.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_5_1.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "print(\"effect of different dense layers cnn performance keeping other parameters same\")\n",
        "print(pt_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of different dense layers cnn performance keeping other parameters same\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | poolsize | num_dense_layers | train_loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        1         |   0.019    |   0.022   |     0.992     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        2         |   0.105    |   0.038   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        3         |   0.096    |   0.042   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        4         |   0.095    |    0.03   |     0.992     |\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfc2pELfup6j"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF_pTXq3Yzx0"
      },
      "source": [
        "**[3.8] affect of adding batch normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "piF4V79LVj0Y",
        "outputId": "df704595-c9c6-41ff-d64b-d7b94c31e71a"
      },
      "source": [
        "#without BN to 3 conv layer architecture\n",
        "history5_41,model5_41=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=3,\n",
        "                               size_dense_layers=[64,32,16],BN=[False]*3)\n",
        "\n",
        "#adding BN to 3 conv layer\n",
        "historyn_1,modeln_1=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[False,0.4],nu_dense_lyrs=3,\n",
        "                               size_dense_layers=[64,32,16],BN=[True]*3)\n",
        "\n",
        "#adding batch normalization to dense layers only\n",
        "history5_6,model5_6=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*5,avg_pooling=[False]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,\n",
        "                                 dropout=[False,0.4],nu_dense_lyrs=3,size_dense_layers=[64,32,16],BN=[False]*5)\n",
        "\n",
        "#applying BN to all layers\n",
        "history5_7,model5_7=create_model(nu_conv_layers=5,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,24,32,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*5,avg_pooling=[False]*5,pool_size=(2,2),pool_strides=[(1,1)]*5,\n",
        "                                 dropout=[False,0.4],nu_dense_lyrs=3,size_dense_layers=[64,32,16],BN=[True]*5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 104s 2ms/step - loss: 0.8117 - acc: 0.7534 - val_loss: 0.0866 - val_acc: 0.9777\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.2870 - acc: 0.9221 - val_loss: 0.1136 - val_acc: 0.9685\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1985 - acc: 0.9476 - val_loss: 0.0473 - val_acc: 0.9866\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1557 - acc: 0.9578 - val_loss: 0.0353 - val_acc: 0.9901\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.1388 - acc: 0.9628 - val_loss: 0.0364 - val_acc: 0.9898\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1133 - acc: 0.9703 - val_loss: 0.0369 - val_acc: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.1019 - acc: 0.9716 - val_loss: 0.0530 - val_acc: 0.9877\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0972 - acc: 0.9741 - val_loss: 0.0509 - val_acc: 0.9897\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0880 - acc: 0.9764 - val_loss: 0.0301 - val_acc: 0.9928\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0810 - acc: 0.9782 - val_loss: 0.0363 - val_acc: 0.9927\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 137s 2ms/step - loss: 0.7771 - acc: 0.7716 - val_loss: 0.0894 - val_acc: 0.9772\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 131s 2ms/step - loss: 0.2601 - acc: 0.9331 - val_loss: 0.0482 - val_acc: 0.9866\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 134s 2ms/step - loss: 0.1791 - acc: 0.9558 - val_loss: 0.0678 - val_acc: 0.9826\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 131s 2ms/step - loss: 0.1416 - acc: 0.9641 - val_loss: 0.0344 - val_acc: 0.9913\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1198 - acc: 0.9689 - val_loss: 0.0514 - val_acc: 0.9883\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 127s 2ms/step - loss: 0.1073 - acc: 0.9731 - val_loss: 0.0345 - val_acc: 0.9918\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0928 - acc: 0.9756 - val_loss: 0.0412 - val_acc: 0.9903\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0916 - acc: 0.9763 - val_loss: 0.0403 - val_acc: 0.9900\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0834 - acc: 0.9793 - val_loss: 0.0416 - val_acc: 0.9909\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 133s 2ms/step - loss: 0.0774 - acc: 0.9797 - val_loss: 0.0409 - val_acc: 0.9894\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 157s 3ms/step - loss: 1.0301 - acc: 0.6631 - val_loss: 0.1527 - val_acc: 0.9625\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 150s 3ms/step - loss: 0.3516 - acc: 0.9047 - val_loss: 0.0651 - val_acc: 0.9817\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.2159 - acc: 0.9428 - val_loss: 0.0478 - val_acc: 0.9868\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1724 - acc: 0.9556 - val_loss: 0.0434 - val_acc: 0.9872\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 148s 2ms/step - loss: 0.1488 - acc: 0.9628 - val_loss: 0.0791 - val_acc: 0.9804\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1333 - acc: 0.9664 - val_loss: 0.0395 - val_acc: 0.9883\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 150s 2ms/step - loss: 0.1208 - acc: 0.9689 - val_loss: 0.0434 - val_acc: 0.9899\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1061 - acc: 0.9727 - val_loss: 0.0484 - val_acc: 0.9884\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1012 - acc: 0.9746 - val_loss: 0.0437 - val_acc: 0.9910\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0968 - acc: 0.9747 - val_loss: 0.0394 - val_acc: 0.9924\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 195s 3ms/step - loss: 0.8793 - acc: 0.7396 - val_loss: 0.0954 - val_acc: 0.9742\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 188s 3ms/step - loss: 0.2694 - acc: 0.9342 - val_loss: 0.0627 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1760 - acc: 0.9590 - val_loss: 0.0549 - val_acc: 0.9864\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 188s 3ms/step - loss: 0.1421 - acc: 0.9662 - val_loss: 0.0393 - val_acc: 0.9905\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1240 - acc: 0.9706 - val_loss: 0.0409 - val_acc: 0.9906\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 185s 3ms/step - loss: 0.1134 - acc: 0.9733 - val_loss: 0.0420 - val_acc: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 182s 3ms/step - loss: 0.1037 - acc: 0.9756 - val_loss: 0.0548 - val_acc: 0.9886\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 186s 3ms/step - loss: 0.1015 - acc: 0.9756 - val_loss: 0.0405 - val_acc: 0.9902\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0898 - acc: 0.9783 - val_loss: 0.0525 - val_acc: 0.9904\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0847 - acc: 0.9804 - val_loss: 0.0528 - val_acc: 0.9876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvTrVBNYut6s"
      },
      "source": [
        "**[3.8.1] Summarizing the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "3LbK0VLFJTpA",
        "outputId": "d57d8da9-4de5-4a2e-be80-794818bbdc1d"
      },
      "source": [
        "pt_bn=PrettyTable()\n",
        "pt_bn.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"maxpool/avgpool?\",\"poolsize\",\"dense layers\",\"batch_normalization_on_convlayers\"\n",
        "                   ,\"train loss\",\"test loss\",\"test accuracy\"]\n",
        "\n",
        "pt_bn.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"No\",np.round(history5_41.history['loss'][9],3),\n",
        "               np.round(model5_41.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_41.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_bn.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"Yes\",np.round(historyn_1.history['loss'][9],3),\n",
        "               np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[0],3),np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_bn.add_row([5,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"No\",np.round(history5_6.history['loss'][9],3),\n",
        "               np.round(model5_6.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_6.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_bn.add_row([5,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"Yes\",np.round(history5_7.history['loss'][9],3),\n",
        "               np.round(model5_7.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_7.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "print(\"effect of batch bormalization on cnn performance keeping other parameters same\")\n",
        "print(pt_bn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of batch bormalization on cnn performance keeping other parameters same\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | poolsize | dense layers | batch_normalization_on_convlayers | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                 No                |   0.081    |   0.036   |     0.993     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                Yes                |   0.077    |   0.041   |     0.989     |\n",
            "|       5       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                 No                |   0.097    |   0.039   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                Yes                |   0.085    |   0.053   |     0.988     |\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4_8pgrkuyNk"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfetlFbtZcpH"
      },
      "source": [
        "**[3.9] Affect of dropout rate On Convolution Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNE2tuHDKYFW"
      },
      "source": [
        "#Dropout =0.1\n",
        "history5_8,model5_8=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[True,0.1],nu_dense_lyrs=2,\n",
        "                               size_dense_layers=[32,16],BN=[True]*3)\n",
        "#dropout=0.5\n",
        "history5_9,model5_9=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[True,0.5],nu_dense_lyrs=2,\n",
        "                               size_dense_layers=[32,16],BN=[True]*3)\n",
        "\n",
        "#dropout=0.8\n",
        "history5_10,model5_10=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=False,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*3,dropout=[True,0.8],nu_dense_lyrs=2,\n",
        "                               size_dense_layers=[32,16],BN=[True]*3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44DRyO5yL_P7"
      },
      "source": [
        "**[3.9.1] Summarizing the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "QRow6KhRL-nJ",
        "outputId": "b572d92d-2f7a-4c5a-ec9b-04947c0599a5"
      },
      "source": [
        "pt_dr=PrettyTable()\n",
        "pt_dr.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"maxpool/avgpool?\",\"pool_size\",\"num_dense_layers\",\"BN\",\"Drp_out_conv_layer\",\n",
        "                   \"train loss\",\"test loss\",\"test accuracy\"]\n",
        "pt_dr.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"Yes\",\"No\",np.round(historyn_1.history['loss'][9],3)\n",
        "               ,np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[0],3),np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dr.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",2,\"Yes\",0.1,np.round(history5_8.history['loss'][9],3)\n",
        "               ,np.round(model5_8.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_8.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dr.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",2,\"Yes\",0.5,np.round(history5_9.history['loss'][9],3)\n",
        "               ,np.round(model5_9.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_9.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_dr.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",2,\"Yes\",0.8,np.round(history5_10.history['loss'][9],3)\n",
        "               ,np.round(model5_10.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_10.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "print(\"effect of different Dropout Rates On cnn performance keeping other parameters same\")\n",
        "print(pt_dr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of different Dropout Rates On cnn performance keeping other parameters same\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | pool_size | num_dense_layers |  BN | Drp_out_conv_layer | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        3         | Yes |         No         |   0.077    |   0.041   |     0.989     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.1         |    0.07    |   0.033   |     0.992     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.5         |   0.119    |    0.03   |     0.991     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.8         |   0.286    |   0.065   |      0.98     |\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_xjKt9jvXtO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luSpN0-vZAx-"
      },
      "source": [
        "**[3.10] affect of data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Zr_PWQxqLxfF",
        "outputId": "8dc68403-26fd-47f2-81e2-91c98387f2e7"
      },
      "source": [
        "history5_11,model5_11,datagen_11=create_model(nu_conv_layers=3,kernel_size=5,kernel_strides=(1,1),padding='valid',feature_maps=[8,16,32],augmentation_done=True,\n",
        "                               max_pooling=[False]*3,avg_pooling=[False]*3,pool_size=(2,2),pool_strides=[(1,1)]*5,dropout=[True,0.5],nu_dense_lyrs=3,\n",
        "                               size_dense_layers=[64,32,16],BN=[True]*3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 174s 290ms/step - loss: 2.1610 - acc: 0.2493 - val_loss: 1.1506 - val_acc: 0.6195\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 165s 275ms/step - loss: 1.5114 - acc: 0.4647 - val_loss: 0.6754 - val_acc: 0.7689\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 165s 275ms/step - loss: 1.1328 - acc: 0.6145 - val_loss: 0.3360 - val_acc: 0.9356\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 165s 275ms/step - loss: 0.8935 - acc: 0.7198 - val_loss: 0.1774 - val_acc: 0.9569\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 165s 275ms/step - loss: 0.7181 - acc: 0.7832 - val_loss: 0.1425 - val_acc: 0.9617\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 165s 276ms/step - loss: 0.6424 - acc: 0.8145 - val_loss: 0.1244 - val_acc: 0.9641\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 166s 277ms/step - loss: 0.5785 - acc: 0.8363 - val_loss: 0.1041 - val_acc: 0.9689\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 162s 270ms/step - loss: 0.5408 - acc: 0.8509 - val_loss: 0.1153 - val_acc: 0.9664\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 160s 267ms/step - loss: 0.5097 - acc: 0.8591 - val_loss: 0.1123 - val_acc: 0.9693\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 164s 274ms/step - loss: 0.4845 - acc: 0.8701 - val_loss: 0.0917 - val_acc: 0.9731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvETujmwqiII"
      },
      "source": [
        "**[3.10.1] Visualizing Some Samples Of Augmented Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "-FVscDAOqhD1",
        "outputId": "3d52ff85-bb16-47ac-cf3c-ec045cb8e3b7"
      },
      "source": [
        "show_samples_of_augmented_images(datagen_11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some samples after performing data augmentation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAG0CAYAAACVAFkxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOMMcaYkvl/7uYqUvap15EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92zSRsN6Mtvk"
      },
      "source": [
        "**[3.10.2] summarizing the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "Z6GE8Z4MMxKE",
        "outputId": "f0d6a166-a7ce-4bf9-8328-70fe689bbb71"
      },
      "source": [
        "pt_aug=PrettyTable()\n",
        "pt_aug.field_names=[\"conv2D layers\",\"kernel\",\"padding\",\"max_pooling/avgpool?\",\"pool_size\",\"dense layers\",\"BN\",\"dropout\",\"data_augmentation\",\n",
        "                    \"train loss\",\"test loss\",\"test accuracy\"]\n",
        "\n",
        "pt_aug.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"Yes\",0.5,\"No\",np.round(history5_9.history['loss'][9],3),\n",
        "                np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[0],3),np.round(modeln_1.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "\n",
        "pt_aug.add_row([3,\"(5,5)\",\"valid\",\"No\",\"(2,2)\",3,\"Yes\",0.5,\"Yes\",np.round(history5_11.history['loss'][9],3),\n",
        "                np.round(model5_11.evaluate(X_test,y_test,verbose=0)[0],3),np.round(model5_11.evaluate(X_test,y_test,verbose=0)[1],3)])\n",
        "print(\"effect of Data Augmentation on cnn performance keeping other parameters same\")\n",
        "print(pt_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "effect of Data Augmentation on cnn performance keeping other parameters same\n",
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | max_pooling/avgpool? | pool_size | dense layers |  BN | dropout | data_augmentation | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |          No          |   (2,2)   |      3       | Yes |   0.5   |         No        |   0.119    |   0.041   |     0.989     |\n",
            "|       3       | (5,5)  |  valid  |          No          |   (2,2)   |      3       | Yes |   0.5   |        Yes        |   0.485    |   0.092   |     0.973     |\n",
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEvh9sRavf9A"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x2dlPXZvHkd"
      },
      "source": [
        "## [4] Summarizing CONCLUSIONS Of CNN ON MNIST DATA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4WcuWpgzEFq"
      },
      "source": [
        "**[4.1] Number of feature maps for MNIST data:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "7WBPtdtrzM5x",
        "outputId": "9d571d7d-64af-422b-9493-b3d1f1a17e14"
      },
      "source": [
        "print(\"Effect of feature maps\")\n",
        "print(pt_fm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Effect of feature maps\n",
            "+---------------+------------+------------+-----------+---------------+\n",
            "| conv2D layers | nu_filters | train loss | test loss | test accuracy |\n",
            "+---------------+------------+------------+-----------+---------------+\n",
            "|       2       |  8 || 16   |   0.024    |   0.038   |     0.988     |\n",
            "|       2       |   2 ||2    |    0.1     |   0.068   |     0.977     |\n",
            "|       3       | 8||16||32  |    0.01    |   0.031   |     0.991     |\n",
            "|       3       |  4||4||4   |   0.077    |    0.06   |      0.98     |\n",
            "+---------------+------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR5dfBWqHkVr"
      },
      "source": [
        "\n",
        "*   Generally more the number of feature maps (number of filters);The more our CNN learns about the different combination of features i.e. some of the combinations can be important some can be redundant for classification.So keeping the number of feature maps reasonably more will give our model good performance.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWwAQ469LzQn"
      },
      "source": [
        "**[4.2] kernel size for the MNIST data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "hAc8gcG_HoGx",
        "outputId": "364b3d30-1c1f-4811-e9cf-1415c6811a8a"
      },
      "source": [
        "print(\"Effect Of kernel Size On MNIST data\")\n",
        "print(pt_ks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Effect Of kernel Size On MNIST data\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n",
            "| conv_layers | kernels size used | padding | train loss | test loss | test accuracy |\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n",
            "|      3      |       (3, 3)      |  valid  |   0.009    |   0.041   |     0.989     |\n",
            "|      3      |       (5, 5)      |  valid  |   0.013    |   0.028   |     0.992     |\n",
            "|      3      |       (7, 7)      |  valid  |   0.021    |   0.029   |     0.991     |\n",
            "+-------------+-------------------+---------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ujB4eeycHg"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   As kernel sizes are nothing but feature extractors;The less kernel size we have we are extracting a lot of features which may lead to overfitting, and kernel size being too large can miss some important features which may lead to underfit.\n",
        "*   So a medium kernel (5,5) has worked good for the given MNIST dataset.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSo1yT2KLv23"
      },
      "source": [
        "**[4.3] Affect Of Padding On MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "1sNDT9QAydwH",
        "outputId": "0135d722-e15a-4ac6-a4cc-4ee903f205c7"
      },
      "source": [
        "print(\"Effect Of padding On Mnist Dataset\")\n",
        "print(pt_pd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Effect Of padding On Mnist Dataset\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n",
            "| conv_layers | kernel size | padding | train loss | test loss | test accuracy |\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n",
            "|      3      |    (5, 5)   |  valid  |   0.011    |   0.032   |      0.99     |\n",
            "|      3      |    (5, 5)   |   same  |    0.01    |   0.031   |     0.991     |\n",
            "+-------------+-------------+---------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0BBagSyv8rC"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Padding='same' is basically adding redundant features/pixels to the original matrix after it is convoluted with an appropraite filter size (i.e. (5,5) for mnist.) ;so as to prserve the diemnsionality of the original matrix.So it will automatically reduce the performance of the Cnn model.\n",
        "*   Padding='valid' will not add redundant pixels after convolution it only keeps the feature that are extracted by kernel.\n",
        "*   Padding='same' is only used when we have input dimensions of image very few and we have Deep CNN.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpHckYWOAUNc"
      },
      "source": [
        "**[4.4] Maxpooling and poolsize On MNIST dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "ewgnnDqSLJ46",
        "outputId": "7975ed7e-fd9e-4989-d313-7c37792abe11"
      },
      "source": [
        "print(\"Maxpooling effect On MNIST dataset\")\n",
        "print(pt_mp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maxpooling effect On MNIST dataset\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | max_pooling | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |   0--0--0   |   0.011    |   0.032   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |   1--1--1   |   0.019    |   0.022   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |  0-0-0-0-0  |    0.02    |   0.029   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |  1-1-1-0-0  |   0.026    |   0.038   |     0.989     |\n",
            "|       5       | (5,5)  |  valid  |  1-1-1-1-1  |   0.029    |   0.044   |     0.986     |\n",
            "+---------------+--------+---------+-------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GJS-kquLp36"
      },
      "source": [
        "* reference https://stats.stackexchange.com/a/374824\n",
        "* Maxpooling is not working that good on MNIST .That can be due to the simplicity of MNIST datset where we have only 1 object in given image.\n",
        "*Maxpooling is used to extract low level sharpest feature from an image,and for doing calculation fast.Low level features may be important for an image that has many objects/shapes in it.But our MNIST dataset is the simplest one.\n",
        "*pool size of (2,2) is working well for MNIST dataset.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOsXAK7zUshQ"
      },
      "source": [
        "**[4.5] Average Pooling On MNIST datset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "sTyHq4gaUxjz",
        "outputId": "e4be92f1-da1e-461d-8e9f-754147419ed1"
      },
      "source": [
        "print(\"average pooling on MNIST dataset\")\n",
        "print(pt_ap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average pooling on MNIST dataset\n",
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | avg_pooling? | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |      No      |   0.011    |   0.032   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |     Yes      |    0.02    |   0.023   |     0.993     |\n",
            "|       5       | (5,5)  |  valid  |      No      |    0.02    |   0.029   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |     Yes      |    0.03    |   0.035   |      0.99     |\n",
            "+---------------+--------+---------+--------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrYEjIC2n82P"
      },
      "source": [
        "\n",
        "\n",
        "*   Average pooling working better than max pooling for MNIST dataset.\n",
        "*   If we observe overall neither maxpooling nor average pooling on MNIST dataset are producing good results.pooling operations are problem specific.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6ZyMFqJRI7L"
      },
      "source": [
        "**[4.6] Adding more number of dense layers to MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "i8stzEkWSFj0",
        "outputId": "bfc96ffd-5fbf-4353-a576-44ac558842d9"
      },
      "source": [
        "print(\"comapring different number of Dense layers\")\n",
        "print(pt_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comapring different number of Dense layers\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | poolsize | num_dense_layers | train_loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        1         |   0.019    |   0.022   |     0.992     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        2         |   0.105    |   0.038   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        3         |   0.096    |   0.042   |      0.99     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |        4         |   0.095    |    0.03   |     0.992     |\n",
            "+---------------+--------+---------+------------------+----------+------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKOU8rUOHUcC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh24cxvWRR3J"
      },
      "source": [
        "**[4.7] Batch normalization and dropout for MNIST data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "PrxDlSL_Rf4n",
        "outputId": "fa562102-e4dd-4bf4-c9b6-4611fee16542"
      },
      "source": [
        "print(\"batch normalization affect\")\n",
        "print(pt_bn)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"train loss {} test loss {} without batch normalization \".format(np.round(history5_41.history['loss'][9],3),np.round(history5_41.history['val_loss'][9],3)))\n",
        "\n",
        "print(\"train loss {} test loss {} with batch normalization \".format(np.round(historyn_1.history['loss'][9],3),np.round(historyn_1.history['val_loss'][9],3)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch normalization affect\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | poolsize | dense layers | batch_normalization_on_convlayers | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                 No                |   0.105    |   0.036   |     0.993     |\n",
            "|       3       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                Yes                |   0.077    |   0.041   |     0.989     |\n",
            "|       5       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                 No                |   0.097    |   0.039   |     0.992     |\n",
            "|       5       | (5,5)  |  valid  |        No        |  (2,2)   |      3       |                Yes                |   0.085    |   0.053   |     0.988     |\n",
            "+---------------+--------+---------+------------------+----------+--------------+-----------------------------------+------------+-----------+---------------+\n",
            "\n",
            "\n",
            "train loss 0.081 test loss 0.036 without batch normalization \n",
            "train loss 0.077 test loss 0.041 with batch normalization \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "E9IkVy4ZLLf-",
        "outputId": "40a59099-9528-4c2f-bb5e-7400d1ed005c"
      },
      "source": [
        "print(\"Without Batch Normalization\")\n",
        "plot_graph(history5_6,model5_6)\n",
        "\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"With batch normalization\")\n",
        "plot_graph(history5_7,model5_7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Batch Normalization\n",
            "test log-loss  0.039378063859247775\n",
            "test accuracy  0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAGeCAYAAABGs1auAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "With batch normalization\n",
            "test log-loss  0.0528347386132984\n",
            "test accuracy  0.9876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAGeCAYAAABGs1auAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4Okw4SCbA5fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAPsEeIq3gxB"
      },
      "source": [
        "\n",
        "\n",
        "*   based On above observations we can say using batch normalization has reduced the difference between train and test loss and also the curve converges a little faster for batch normalization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "v48xUDxARvDG",
        "outputId": "f3aea3e3-e7c8-4954-f09c-65644de1f215"
      },
      "source": [
        "print(\"dropout effect\")\n",
        "print(pt_dr)\n",
        "\n",
        "print(\"\\nwithout using dropout on the convolution layers :\")\n",
        "print(\"train loss \",np.round(historyn_1.history['loss'][9],2))\n",
        "print(\"test loss \",np.round(historyn_1.history['val_loss'][9],2))\n",
        "\n",
        "print(\"using dropout on convolution layers \")\n",
        "print(\"train loss \",np.round(history5_9.history['loss'][9],2))\n",
        "print(\"test loss \",np.round(history5_9.history['val_loss'][9],2))\n",
        "      \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dropout effect\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | maxpool/avgpool? | pool_size | num_dense_layers |  BN | Drp_out_conv_layer | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        3         | Yes |         No         |   0.077    |   0.041   |     0.989     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.1         |    0.07    |   0.033   |     0.992     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.5         |   0.119    |    0.03   |     0.991     |\n",
            "|       3       | (5,5)  |  valid  |        No        |   (2,2)   |        2         | Yes |        0.8         |   0.286    |   0.065   |      0.98     |\n",
            "+---------------+--------+---------+------------------+-----------+------------------+-----+--------------------+------------+-----------+---------------+\n",
            "\n",
            "without using dropout on the convolution layers :\n",
            "train loss  0.08\n",
            "test loss  0.04\n",
            "using dropout on convolution layers \n",
            "train loss  0.12\n",
            "test loss  0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Ct-CoaGuqn"
      },
      "source": [
        "* Batch normalization worked for MNIST data to improve performance.\n",
        "\n",
        "*   As far as mnist dataset is concerned having dropout or not in both cases the model is performing similar.Large dropouts are always avoided as they always produces more loss.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX7g-_JURX_z"
      },
      "source": [
        "**[4.8] Data Augmentation For MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "sSPS3kPrQO-x",
        "outputId": "12267140-2541-4aa6-8927-634a064b1692"
      },
      "source": [
        "print(pt_aug)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n",
            "| conv2D layers | kernel | padding | max_pooling/avgpool? | pool_size | dense layers |  BN | dropout | data_augmentation | train loss | test loss | test accuracy |\n",
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n",
            "|       3       | (5,5)  |  valid  |          No          |   (2,2)   |      3       | Yes |   0.5   |         No        |   0.119    |   0.041   |     0.989     |\n",
            "|       3       | (5,5)  |  valid  |          No          |   (2,2)   |      3       | Yes |   0.5   |        Yes        |   0.485    |   0.092   |     0.973     |\n",
            "+---------------+--------+---------+----------------------+-----------+--------------+-----+---------+-------------------+------------+-----------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi93zTmEihIi"
      },
      "source": [
        "\n",
        "\n",
        "*   Doing data augmentation has not produced good results for MNIST dataset.\n",
        "\n"
      ]
    }
  ]
}